{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修改参考文献bib格式，论文题目的每个单词开头字母均大写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除相关介词的大写\n",
    "e_list = ['of', 'the', 'for', 'with','and','in','to','on','at']\n",
    "\n",
    "\n",
    "def new_str(x):\n",
    "    \"\"\"将字符串中的单词（除去预先给定的单词列表）首字母大写\n",
    "\n",
    "    Args:\n",
    "        x (_type_): 预处理字符串\n",
    "\n",
    "    Returns:\n",
    "        _type_: 除给定单词之外单词首字母大写后的字符串\n",
    "    \"\"\"\n",
    "    return ' '.join([a.title() if (not a in e_list and not a.isupper()) else a for a in x.split()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  title={{A Time-Dependent Hamilton-Jacobi Formulation of Reachable Sets for Continuous Dynamic Games}},\n",
      "\n",
      "\ttitle={{Control Barrier Function Based Quadratic Programs for Safety Critical Systems}},\n",
      "\n",
      "\ttitle={{Adaptive Control-Based Barrier Lyapunov Functions for A Class of Stochastic Nonlinear Systems with Full State Constraints}},\n",
      "\n",
      "\ttitle={{Domain Randomization for Transferring Deep Neural Networks From Simulation to the Real World}},\n",
      "\n",
      "\ttitle={{Airsim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles}},\n",
      "\n",
      "\ttitle={{CARLA: An Open Urban Driving Simulator}},\n",
      "\n",
      "\ttitle={{Mastering the Game of Go with Deep Neural Networks and Tree Search}},\n",
      "\n",
      "\ttitle={{Learning Agile and Dynamic Motor Skills for Legged Robots}},\n",
      "\n",
      "\ttitle={{A Tour of Reinforcement Learning: The View From Continuous Control}},\n",
      "\n",
      "\ttitle={{Control Barrier Functions: Theory and Applications}},\n",
      "\n",
      "\ttitle={{Reinforcement Learning Solution for HJB Equation Arising in Constrained Optimal Control Problem}},\n",
      "\n",
      "\ttitle={{Self-Paced Prioritized Curriculum Learning with Coverage Penalty in Deep Reinforcement Learning}},\n",
      "\n",
      "\ttitle={{Barrier Function Based Model Predictive Control}},\n",
      "\n",
      "\ttitle={{Multiobjective Reinforcement Learning: A Comprehensive Overview}},\n",
      "\n",
      "\ttitle={{Robust Adversarial Reinforcement Learning}},\n",
      "\n",
      "\ttitle={{Meta Reinforcement Learning for Sim-To-Real Domain Adaptation}},\n",
      "\n",
      "\ttitle={{Sim-To-Real Transfer with Neural-Augmented Robot Simulation}},\n",
      "\n",
      "\ttitle={{A Formal Methods Approach to Interpretable Reinforcement Learning for Robotic Planning}},\n",
      "\n",
      "\ttitle={{Sim-To-Real Transfer in Deep Reinforcement Learning for Robotics: A Survey}},\n",
      "\n",
      "\ttitle={{A General Safety Framework for Learning-Based Control in Uncertain Robotic Systems}},\n",
      "\n",
      "\ttitle={{Actor-Critic Reinforcement Learning for Control with Stability Guarantee}},\n",
      "\n",
      "\ttitle={{Data-Driven Approximate Q-Learning Stabilization with Optimality Error Bound Analysis}},\n",
      "\n",
      "\ttitle={{Sparse Proximal Reinforcement Learning Via Nested Optimization}},\n",
      "\n",
      "\ttitle={{Sequential Decision Making with Coherent Risk}},\n",
      "\n",
      "\ttitle={{基于干扰观测器的四旋翼无人机轨迹跟踪鲁棒控制}},\n",
      "\n",
      "\ttitle={{Correct-By-Design Control Barrier Functions for Euler-Lagrange Systems with Input Constraints}},\n",
      "\n",
      "\ttitle={{A Control Barrier Perspective on Episodic Learning Via Projection-To-State Safety}},\n",
      "\n",
      "\ttitle={{A Reinforcement Learning Approach to Autonomous Decision Making of Intelligent Vehicles on Highways}},\n",
      "\n",
      "\ttitle={{Sim-To-Real: Six-Legged Robot Control with Deep Reinforcement Learning and Curriculum Learning}},\n",
      "\n",
      "\ttitle={{Safe Reinforcement Learning: A Control Barrier Function Optimization Approach}},\n",
      "\n",
      "\ttitle={{A Comprehensive Survey on Safe Reinforcement Learning}},\n",
      "\n",
      "\ttitle={{无人机安全控制系统技术: 进展与展望}},\n",
      "\n",
      "\ttitle={{无人机认知防碰撞系统安全边界研究}},\n",
      "\n",
      "\ttitle={{机器人安全性研究现状及发展趋势}},\n",
      "\n",
      "\ttitle={{Integrating Guidance Into Relational Reinforcement Learning}},\n",
      "\n",
      "\ttitle={{Safety Robustness of Reinforcement Learning Policies: A View From Robust Control}},\n",
      "\n",
      "\ttitle={{Soft Actor-Critic Algorithms and Applications}},\n",
      "\n",
      "\ttitle={{Proximal Policy Optimization Algorithms}},\n",
      "\n",
      "\ttitle={{ROS: An Open-Source Robot Operating System}},\n",
      "\n",
      "    title= {{{{Benchmarking Safe Exploration in Deep Reinforcement Learning}}}},\n",
      "\n",
      "  title={{Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation}},\n",
      "\n",
      "title = {{{{Grandmaster Level in Starcraft II Using Multi-Agent Reinforcement Learning}}}},\n",
      "\n",
      "title = {{{{Towards Playing Full MOBA Games with Deep Reinforcement Learning}}}},\n",
      "\n",
      "    title= {{{{Spinning Up in Deep Reinforcement Learning}}}},\n",
      "\n",
      "  title={{Addressing Function Approximation Error in Actor-Critic Methods}},\n",
      "\n",
      "  title={{Continuous Control with Deep Reinforcement Learning}},\n",
      "\n",
      "  title={{A Pursuit-Evasion Game Between Two Identical Differential Drive Robots}},\n",
      "\n",
      "title = {{{{The Robotarium}}}},\n",
      "\n",
      "  title={{Hierarchical Macro Strategy Model for Moba Game Ai}},\n",
      "\n",
      "  title={{A Generalist Agent}},\n",
      "\n",
      "    title= {{{{Conservative Safety Critics for Exploration}}}},\n",
      "\n",
      "    title= {{{{Safe Reinforcement Learning Via Shielding}}}},\n",
      "\n",
      "    title= {{{{Towards Safe Control of Continuum Manipulator Using Shielded Multiagent Reinforcement Learning}}}},\n",
      "\n",
      "title = \"Reachability-Based Safe Learning with Gaussian Processes\",\n",
      "\n",
      "  title={{Learning-Based Model Predictive Control: Toward Safe Learning in Control}},\n",
      "\n",
      "  title={{Consensus-Based Control Barrier Function for Swarm}},\n",
      "\n",
      "  title={{On Making Robots Understand Safety: Embedding Injury Knowledge Into Control}},\n",
      "\n",
      "  title={{Learning Human Objectives By Evaluating Hypothetical Behavior}},\n",
      "\n",
      "  title={{Safe Reinforcement Learning Via Statistical Model Predictive Shielding.}},\n",
      "\n",
      "  title={{Safe Reinforcement Learning Using Black-Box Reachability Analysis}},\n",
      "\n",
      "  title={{Efficient Off-Policy Safe Reinforcement Learning Using Trust Region Conditional Value At Risk}},\n",
      "\n",
      "  title={{TRC: Trust Region Conditional Value at Risk for Safe Reinforcement Learning}},\n",
      "\n",
      "    title= {{{{Sablas: Learning Safe Control for Black-Box Dynamical Systems}}}},\n",
      "\n",
      "    title= {{{{Learning Observation-Based Certifiable Safe Policy for Decentralized Multi-Robot Navigation}}}},\n",
      "\n",
      "  title={{Safety-Critical Model Predictive Control with Discrete-Time Control Barrier Function}},\n",
      "\n",
      "  title={{Enhancing Feasibility and Safety of Nonlinear Model Predictive Control with Discrete-Time Control Barrier Functions}},\n",
      "\n",
      "  title={{Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents}},\n",
      "\n",
      "  title={{Mujoco: A Physics Engine for Model-Based Control}},\n",
      "\n",
      "  title={{Off-Policy Actor-Critic}},\n",
      "\n",
      "  title={{Q-Learning}},\n",
      "\n",
      "  title={{Playing Atari with Deep Reinforcement Learning}},\n",
      "\n",
      "  title={{Deepmind Control Suite}},\n",
      "\n",
      "  title={{Asynchronous Methods for Model-Based Reinforcement Learning}},\n",
      "\n",
      "  title={{Locally Lipschitz Functions, Cofinal Completeness, and UC Spaces}},\n",
      "\n",
      "  title={{Lectures on Convex Optimization}},\n",
      "\n",
      "  title={{Safety-Critical and Constrained Geometric Control Synthesis Using Control Lyapunov and Control Barrier Functions for Systems Evolving on Manifolds}},\n",
      "\n",
      "  title={{Control Barrier Function Based Quadratic Programs with Application to Bipedal Robotic Walking}},\n",
      "\n",
      "  title={{Applications of the Theory of Matrices}},\n",
      "\n",
      "    title= {{{{Application of Reinforcement Learning Based on Neural Network to Dynamic Obstacle Avoidance}}}},\n",
      "\n",
      "  title={{Optimal Path Planning Approach Based on Q-Learning Algorithm for Mobile Robots}},\n",
      "\n",
      "  title={{Thor: Human-Robot Navigation Data Collection and Accurate Motion Trajectories Dataset}},\n",
      "\n",
      "  title={{Mobile Robots Exploration Through Cnn-Based Reinforcement Learning}},\n",
      "\n",
      "  title={{Deep Reinforcement Learning in A 3-D Blockworld Environment}},\n",
      "\n",
      "  title={{Deep Reinforcement Learning with Successor Features for Navigation Across Similar Environments}},\n",
      "\n",
      "  title={{Deep Reinforcement Learning Robot for Search and Rescue Applications: Exploration in Unknown Cluttered Environments}},\n",
      "\n",
      "  title={{Learning to Navigate in Cities Without A Map}},\n",
      "\n",
      "  title={{Role Playing Learning for Socially Concomitant Mobile Robot Navigation}},\n",
      "\n",
      "  title={{Ant Colony Optimization: Overview and Recent Advances}},\n",
      "\n",
      "  title={{An Efficient Improved Artificial Potential Field Based Regression Search Method for Robot Path Planning}},\n",
      "\n",
      "  title={{A Novel Robust Lane Change Trajectory Planning Method for Autonomous Vehicle}},\n",
      "\n",
      "  title={{基于改进人工势场法的智能车辆超车路径规划研究}},\n",
      "\n",
      "  title={{Path Planning with Modified A Star Algorithm for A Mobile Robot}},\n",
      "\n",
      "  title={{The Dynamic Window Approach to Collision Avoidance}},\n",
      "\n",
      "  title={{基于改进人工势场法的移动机器人路径规划方法}},\n",
      "\n",
      "  title={{基于人工势场法的 AUV 避障算法研究综述}},\n",
      "\n",
      "   title={{基于改进人工势场法的无人车路径规划算法}},\n",
      "\n",
      "  title={{Collision Avoidance Method of Autonomous Vehicle Based on Improved Artificial Potential Field Algorithm}},\n",
      "\n",
      "  title={{移动机器人运动规划中的深度强化学习方法}},\n",
      "\n",
      "  title={{A Comparison Study of Cooperative Q-Learning Algorithms for Independent Learners}},\n",
      "\n",
      "  title={{Value-Decomposition Networks for Cooperative Multi-Agent Learning}},\n",
      "\n",
      "  title={{Qmix: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning}},\n",
      "\n",
      "  title={{Qtran: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning}},\n",
      "\n",
      "  title={{Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments}},\n",
      "\n",
      "  title={{Reducing Overestimation Bias in Multi-Agent Domains Using Double Centralized Critics}},\n",
      "\n",
      "  title={{Human-Level Control Through Deep Reinforcement Learning}},\n",
      "\n",
      "  title={{Agent57: Outperforming the Atari Human Benchmark}},\n",
      "\n",
      "  title={{Starcraft Ii: A New Challenge for Reinforcement Learning}},\n",
      "\n",
      "  title={{Top-K Off-Policy Correction for A REINFORCE Recommender System}},\n",
      "\n",
      "  title={{Generative Adversarial Networks}},\n",
      "\n",
      "  title={{Mastering Complex Control in Moba Games with Deep Reinforcement Learning}},\n",
      "\n",
      "  title={{Reinforcement Learning to Optimize Long-Term User Engagement in Recommender Systems}},\n",
      "\n",
      "  title={{Interactive Recommendation with User-Specific Deep Reinforcement Learning}},\n",
      "\n",
      "  title={{Vision-Language Recommendation Via Attribute Augmented Multimodal Reinforcement Learning}},\n",
      "\n",
      "  title={{Fast Reachable Set Approximations Via State Decoupling Disturbances}},\n",
      "\n",
      "  title={{Algorithm for Overcoming the Curse of Dimensionality for Time-Dependent Non-Convex Hamilton--Jacobi Equations Arising From Optimal Control and Differential Games Problems}},\n",
      "\n",
      "  title={{Hopf--Lax-Type Formula Forut+ H (U, Du)= 0}},\n",
      "\n",
      "  title={{Reachability-Based Safe Learning with Gaussian Processes}},\n",
      "\n",
      "  title={{Safe Economic Model Predictive Control of Nonlinear Systems}},\n",
      "\n",
      "  title={{Safe Optimization of Highway Traffic with Robust Model Predictive Control-Based Cooperative Adaptive Cruise Control}},\n",
      "\n",
      "  title={{Nonsmooth Barrier Functions with Applications to Multi-Robot Systems}},\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f=open('bib.bib','r',encoding='UTF-8')#读取想要修改的bib参考文献\n",
    "fw = open('bib_update.bib','w')#写入新的bib文件中\n",
    "lines=f.readlines()\n",
    "for line in lines:\n",
    "    # if(line[2:7]==\"title\"):\n",
    "    if(\"title\" in line[0:10] and \"booktitle\" not in line[0:10]):\n",
    "        new_line = line.replace('{', '{{')\n",
    "        new_line = new_line.replace('}', '}}')\n",
    "        # print(new_line[0:9])\n",
    "        # final_line = new_line[0:9] + string.capwords(new_line[9:])+'\\n'\n",
    "        # final_line = new_line[0:9] + new_line[9:].title()\n",
    "        final_line = new_line[0:9] + new_str(new_line[9:])+'\\n'\n",
    "        fw.write(final_line)\n",
    "        print(final_line)\n",
    "    else:\n",
    "        fw.write(line)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing If One of This Will Work EVERYWHERE, Also in CHINA, in the Run.\n"
     ]
    }
   ],
   "source": [
    "f = 'Testing if one of this will work EVERYWHERE, also in CHINA, in the run.'\n",
    "\n",
    "print(new_str(f))\n",
    "#Testing If One of This Will Work EVERYWHERE, Also In CHINA, In the Run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('gobigger')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c7484b3574347463e16b31029466871583b0d4e5c4ad861e8848f2d3746b4de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
